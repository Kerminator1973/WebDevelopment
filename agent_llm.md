# Агентская модель в LLM

MCP = _Model Context Protocol_.

Разработчик MCP - Anthropic, в 2024 году.

RAG (Retrieval-Augmented Generation) в LLM — это техника, которая улучшает ответы больших языковых моделей, позволяя им получать и использовать внешние, актуальные данные (из баз знаний, документов, интернета) перед генерацией ответа, а не полагаться только на свои "замороженные" обучающие данные.

MCP - это как USB-C для агентских систем.

LLM - это клиент агентских систем.

Примеры агентов: PostgreSQL, Google Drive, GitHub.

Чаще всего агенты предоставляют LLM доступ к ресурсам: папкам и файлам, что позволяет LLM сформировать больший контекст, получая доступ к файлам проекта, настройкам, и т.д.

Агенты встраиваются в IDE: [Windsurf](https://windsurf.com/) (см. Cascade), [Cursor](https://cursor.com/) (см. Composer), Visual Studio Code, Visual Studio 2026, GigaIDE, IntelliJ AI, Amazon CodeWhisperer Studio, GitHub Codespaces. В большинстве случаев, в качестве основы IDE используется Visual Studio Code.

>Cursor - в режиме **Plan** задаёт уточняющие вопросы и формирует Markdown-файл с описание задачи и списокм того, чтоб нужно сделать с кодом. Далее Cursor работает уже с этим списком.
>
>В бесплатной версии есть GPT 5.2. Хорошо подходит для проектирования, прототипов и быстрых экспериментов. Позволяет выполнять регистрацию на "10 минутные" почтовые аккаунты.
>
>Примеры 10-минутной (disposable) почты: [TMailor.com](https://tmailor.com/), [Moakt](https://moakt.com/ru), [MailSAC](https://mailsac.com/).
>
>Рекомендуется для прочтения [Осознанный вайб-кодинг](https://habr.com/ru/articles/982452/) by davidaganov.

Рекомендуется для прочтения статья [Claude Code научили работать с Chrome. Вот насколько это опасно](https://habr.com/ru/news/978712/) by **python_leader**. Появилась новый вид уязвимостей **Prompt Injection** - документы, которые включаются в контекст LLM, например, электронные письма содержат вставки, вынуждающие LLM формировать команды, наносящие ущерб пользователю системы, например, удалять всю почту пользователя без подтверждения. Браузерные расширения Anthropic развиваются в направлении создания специальной политики информационной безопасности, которая требует подтверждения пользователя для критичных операций выполняемых агентами, таких как: публикации, покупки, предоставление другим пользователям доступа к ресурсам системы.

Agent Mode в Visual Studio Code: `File -> Preference -> Settings`, искать настройку `chat.agent.enabled`.

Agent Mode в Visual Studio Code получает доступ к окну "Output" (результаты компиляции), Linter-у, умеет напрямую работать с браузером (доступ к DOM, возможно - отладка). Также имеет доступ к консоли (Terminal), т.е. LLM может выполнять команды операционной системы.

Можно добавить дополнительные MCP-сервера через магазин plug-in-ов.

Почему доступ для разработчиков в сильных моделях стоит дорого: LLM активно взаимодействует с агентами через MCP, в частности, для устранения ошибок сборки и улучшения кода на основании Linter-ов. Такого рода взаимодействие требует огромного количества промптов.

Выгрузка больших проектов, т.е. создание большого контекста, также приводит к активному расходу токенов.

Резюмируя причины дороговизны мощного ИИ:

- требуется более мощное оборудование (размер ОЗУ и SSD) для создания инференса. Мощность LLM определяется сотниями миллиардов параметров
- загрузка контекста в инференс из локальной машины требует большего объёма памяти
- частота выполнения запросов к LLM от агентов значительно выше, чем в классической модели
