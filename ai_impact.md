# Влияние ИИ на разработку программного кода

Сначала приведу ответы на наиболее важные вопросы, а потом дам разъяснения по каждому из ответов.

Даёт ли использование ИИ значительные преимущества при разработке программного кода: ДА!

Приводит ли использование ИИ к повышению эффективности труда программиста: Несомненно!

Являются ли мощные LLM кратно более полезными, чем басплатные LLM: ДА, являются!

Может ли применение ИИ привести к деградации программного продукта: ДА и, к сожалению, вероятность этого высока!

Может ли любой коллектив извлечь пользу от использования агентской модели LLM: НЕТ. Коллектив должен быть достаточно зрелым для этого.

Является ли коммерчески выгодным для компании оплачивать сотрудникам мощные LLM: ДА, в общем случае, экономический эффект является значимым.

Может ли ИИ быть эффективно использован в любом проекте: НЕТ. ИИ лучше всего работает на маленьких проектах. Чем больше технология и алгоритмы похожи на 100 тысяч таких же, уже написанных, тем выше будет качество кода сгенерированного ИИ.

## Как возникает деградация программого продукта (на реальных примерах)

Студент генерировал код на Python для институтской задачи по курсу "цифровая лингвистика". По условиям задачи следовало выполнить векторизацию исходных документов, построив по каждому из документов вектор, содержащий частоту использования каждого слова, встречаемого в любом из документов. Затем нужно было извлечь частоту использования конкретного слова из конкретного документа.

В действительности, нам нужно было просто извлечь элемент из двухмерной матрицы:

```py
# Находим индекс столбца в матрице документов и слов
word_index = list(feature_names).index(word)
return tf_matrix[number_of_doc, word_index]
```

Вот, что сгенерировал ИИ:

```py
# Находим индекс столбца в матрице документов и слов
word_index = list(feature_names).index(word)
tf_values = tf_matrix[:, word_index].toarray().flatten()
return tf_values[number_of_doc]
```

Сразу замечу, что код сгенерированный ИИ является работоспособным, он выглядит очень профессионально, но что если попытаться оценить его эффективность?

Код извлекает весь столбец значений для этого слова по всем документам. Символ двоеточия ":" это slice, т.е. эквивалент [:], в данном случае означающий берём все строки. При этом используется только один конкретный столбец. Mетод toarray() преобразует полученный столбец в массив NumPy. Метод flatten() преобразует массив NumPy в одномерный вектор - строку, выполяя "уплощение" данных:

```py
tf_values = tf_matrix[:, word_index].toarray().flatten()
```

Далее, используя индекс документа, мы получаем частоту (TF), или IDF указанного слова в документе:

```py
return tf_values[number_of_doc]
```

Т.е. ИИ создал два новых массива и выполнил две сложных операции преобразования типов контейнеров вместо того, чтобы просто взять один элемент матрицы. Решение ИИ на два-три порядка хуже, чем код написанный программистом.

Проблема состоит в том, что если не вчитываться в код и не проверять его эффективность на постоянной основе, можно включить в промышленное решение множество супер-не эффективных алгоритмов, которые будут приводить к огромному расходу ресурсов и, косвенно, наносить коммерческий ущерб компании.
