# Профилирование SQL-запросов

Для оценки поведения приложений использующих СУБД рекомендуется использовать профилировщики.

Для Microsoft SQL Server можно установить профилировщик вместе с Management Studio.

## Как искать проблемы выполнения запросов в Postgres - pgBadger (PostgreSQL Query Analyzer)

Даёт понимание, что на самом деле происходит в Postgres, минимизируя затраты времени на изучение логов.

Источник: https://medium.com/@reliabledataengineering/15-sql-optimization-tools-that-make-queries-10x-faster-8629ac451d97

Логи запросов PostgreSQL полны, но нечитаемы. Тысячи строк показывают время выполнения, планы и ошибки — но нет чёткого представления о том, что именно снижает производительность.

pgBadger преобразует чистые логи PostgreSQL в полезные HTML-отчеты, показывающие:

- Самые медленные запросы (с фактическим временем выполнения);
- Наиболее часто выполняемые запросы (цели оптимизации с высоким уровнем влияния);
- Запросы, вызывающие ошибки;
- Анализ ожидания блокировок;
- Использование временных файлов;
- Паттерны соединений.

Типовые логи Postgres выглядят следующим образом:

```shell
2025-02-07 14:23:11 UTC [12345]: LOG: duration: 45231.234 ms statement: SELECT...
2025-02-07 14:23:56 UTC [12346]: LOG: duration: 123.456 ms statement: SELECT...
```

pgBadger позволяет создать отчёта из логов:

```shell
pgbadger /var/log/postgresql/postgresql-*.log -o report.html
```

Создаёт красивый HTML-отчет, показывающий: 10 самых медленных запросов, варианты быстрых решений проблем производительности.

Инкрементальная генерация отчетов вместо обработки всего лога:

```shell
pgbadger --last-parsed /var/log/last_parsed.log /var/log/postgresql/postgresql-*.log -o incremental-report.html
```

ля больших логов (>10Гб) следует использовать сэмплинг:

```shell
# Анализируем 10% логов
pgbadger --sample 10 large_logfile.log

# Делим на временные отрезки
pgbadger --begin "2025-02-07 00:00:00" --end "2025-02-07 23:59:59" postgresql.log
```
